# **Vehicle Detection**

## Writeup

---

**Vehicle Detection Project**

The goals / steps of this project are the following:

* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier
* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.
* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.
* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.
* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.
* Estimate a bounding box for vehicles detected.


[//]: # (Image References)

[classifiers_heatmaps]: ./output_images/classifiers.jpg "Heat maps of individual classifiers"
[joint_heatmaps]: ./output_images/heatmap.jpg "Joint heat map with the selected classifiers"
[winsearch]: ./output_images/winsearch.jpg "Window search visualization"

[segment]: ./output_images/segment.jpg "Vehicles segmentation visualization"

---

### Code overview

The core functions used in this project are combined into `vdetect.py` Python module. `scaler.py` contains the `FeatureScaler` class used to perform scaling on different sets of features extracted from an image. `train.py` is a script that performs training of a number of classifiers on the vehicles/non-hevicles data. All the resulting media files are generated by the `genmedia.py` script.


### Feature engineering

This project uses a feature preparation method (see `vdetect.extract_features`) that combines three sets of features, extracted from a (64, 64, 3) image:

* HOG features, extracted from the grayscale transformation of the original image
* Binned version of the the grayscale transformation of the original image: (64, 64) -> (32, 32) -> flatten
* Combined histogram of color channels: R, G, B, H (of HLS), U (of LUV)

Upon extraction, the three feature sets are returned separately as values in a dictionary. Further, in `vdetect.prepare_train_test_data_single_class` and `vdetect.prepare_train_test_data`, dictionaries from individual images are combined together, shuffled, and separated into training and testing sets. To perform scaling on each feature sets separately, the `scaler.FeatureScaler` class is used. When constructed, `FeatureScaler` accepts a dictionary of training sets and fits a `sklearn.preprocessing.StandardScaler` on each feature set.


```python

scaler = FeatureScaler(train_dict)
```

Function `vdetect.create_feature_extractor` accepts an instance of `FeatureScaler` and returns a closure that performs feature extraction and scaling given an image (64, 64, 3).

```
extract = vdetect.create_feature_extractor(scaler, hyperparams)
fvec = extract(im)
```

Feature extraction procedure is parameterized with the following hyperparameters (the given set is the one finally chosen for the project; other combinations of parameters were varied during the ML experimentation phase):

```json
{
    "hog_n_orient": 9,
    "hog_cell_sz": 8,
    "hog_block_sz": 2,
    "binning_sz": 32,
    "hist_bins": 32
}
```

### Sliding window

The sliding window strategy applied in this project is based on a series of sliding window loops with windows of varying sizes over different search area.

Initially, the main region of interest (ROI) is chosen in the middle of the image by discarding the top and the bottom parts of the image, as well as the left part, not belonging to the road (see `vdetect.define_main_region_custom_2`). As such, the only the road projection is further searched.

The scaling strategy (`vdetect.define_loops_custom_3`) is the following:

* Search the entire ROI with square windows of 256 pixels and step of 1/4 of the size (64 pixels)
* Shrink the ROI from the bottom by 64 pixels, and perform search with size of 128 pixels and step of 32 pixels
* Shrink the ROI from the bottom by 64 more pixels, from the top by 64 pixels, and perform search with size of 64 pixels and step of 16 pixels.

![alt text][winsearch]


### Machine learning

To detect vehicles in the road images, several supervised classifiers (implemented in Scikit-learn) are trained given the vehicle/non-vehicle data, which was fed through the feature extraction routine, described earlier.

The effects of different classifiers and their parameterization on the test images were evaluated graphically, by visual analysis of the heat maps produced by an individual classifiers:

![alt text][classifiers_heatmaps]

The example above shows result of heat maps visualization for the following set of classifiers:

* `decision_tree_default`: decision tree classifier with default parameters
* `decision_tree_bigger_split`: decision tree classifier with `min_samples_split=5`
* `random_forest_default`: random forest classifier with default parameters
* `grad_boost_default`: gradient boosting classifier with default parameters

The best-performing classifiers in the given set are `decision_tree_default` and `random_forest_default`, as they are least susceptible to false positives. These two classifiers were used to create the resulting joint heat map, further used for vehicles segmentation (heat maps in the following image are marked with the maximal value on the corresponding map, `np.max(heatmap)`):

![alt text][joint_heatmaps]

### Vehicles segmentation

Segmentation of image regions with vehicles (implemented in `vdetect.segment_vehicles`) is based on thresholding a heat map produced by sliding window search and ML-based classification, followed by connected components detection (using `cv2.connectedComponentsWithStats`).

The threshold is defined as a ratio of the maximal value of a heat map (in this project: `0.7 * np.max(heatmap)`).

False positive in images with no vehicles result in low value of `np.max(heatmap)`. Such images are ruled out by comparing `np.max(heatmap)` with the `low_limit` threshold (in this project: 10).

Results of vehicles segmentation are shown on the following figure:

![alt text][segment]

### Shortcomings and possible improvements

A more extensive exploration of different combinations of ML classifiers and feature extraction routines should be done do devise a more robust vehicle detector. In addition, it is beneficial to use a larger data set may for training.

The sliding window search routine should take into account previously estimated lane region.

A tracking mechanism should be developed to capture frame-to-frame correlation.
